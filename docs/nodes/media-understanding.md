---
summary: "Entendimento de imagem/√°udio/v√≠deo de entrada (opcional) com fallbacks de provedor + CLI"
read_when:
  - Projetando ou refatorando o entendimento de m√≠dia
  - Ajustando o pr√©-processamento de √°udio/v√≠deo/imagem de entrada
---
# Entendimento de M√≠dia (Entrada) ‚Äî 17-01-2026

O ZERO pode **resumir m√≠dias de entrada** (imagem/√°udio/v√≠deo) antes que o pipeline de resposta seja executado. Ele auto-detecta quando ferramentas locais ou chaves de provedores est√£o dispon√≠veis e pode ser desativado ou personalizado. Se o entendimento estiver desligado, os modelos ainda recebem os arquivos/URLs originais normalmente.

## Objetivos

- Opcional: pr√©-digerir a m√≠dia de entrada em texto curto para roteamento mais r√°pido + melhor an√°lise de comandos.
- Preservar a entrega da m√≠dia original ao modelo (sempre).
- Suportar **APIs de provedores** e **fallbacks de CLI**.
- Permitir m√∫ltiplos modelos com fallback ordenado (erro/tamanho/timeout).

## Comportamento de alto n√≠vel

1) Coleta os anexos de entrada (`MediaPaths`, `MediaUrls`, `MediaTypes`).
2) Para cada capacidade habilitada (imagem/√°udio/v√≠deo), seleciona os anexos por pol√≠tica (padr√£o: **primeiro**).
3) Escolhe a primeira entrada de modelo eleg√≠vel (tamanho + capacidade + autentica√ß√£o).
4) Se um modelo falhar ou a m√≠dia for muito grande, **recorre (fallback) √† pr√≥xima entrada**.
5) Em caso de sucesso:
   - O `Body` torna-se um bloco `[Image]`, `[Audio]` ou `[Video]`.
   - √Åudio define `{{Transcript}}`; a an√°lise de comandos usa o texto da legenda quando presente, caso contr√°rio, a transcri√ß√£o.
   - Legendas s√£o preservadas como `User text:` dentro do bloco.

Se o entendimento falhar ou estiver desativado, **o fluxo de resposta continua** com o corpo original + anexos.

## Vis√£o geral da configura√ß√£o

`tools.media` suporta **modelos compartilhados** e sobrescritas por capacidade:

- `tools.media.models`: lista de modelos compartilhados (use `capabilities` para filtrar).
- `tools.media.image` / `tools.media.audio` / `tools.media.video`:
  - padr√µes (`prompt`, `maxChars`, `maxBytes`, `timeoutSeconds`, `language`)
  - sobrescritas de provedor (`baseUrl`, `headers`, `providerOptions`)
  - op√ß√µes de √°udio Deepgram via `tools.media.audio.providerOptions.deepgram`
  - **lista `models` por capacidade** opcional (preferencial antes dos modelos compartilhados)
  - pol√≠tica de `attachments` (`mode`, `maxAttachments`, `prefer`)
  - `scope` (gating opcional por canal/chatType/chave de sess√£o)
- `tools.media.concurrency`: execu√ß√µes simult√¢neas m√°ximas por capacidade (padr√£o **2**).

```json5
{
  tools: {
    media: {
      models: [ /* lista compartilhada */ ],
      image: { /* sobrescritas opcionais */ },
      audio: { /* sobrescritas opcionais */ },
      video: { /* sobrescritas opcionais */ }
    }
  }
}
```

### Entradas de modelo

Cada entrada em `models[]` pode ser um **provedor** ou **CLI**:

```json5
{
  type: "provider",        // padr√£o se omitido
  provider: "openai",
  model: "gpt-5.2",
  prompt: "Descreva a imagem em <= 500 caracteres.",
  maxChars: 500,
  maxBytes: 10485760,
  timeoutSeconds: 60,
  capabilities: ["image"], // opcional, usado para entradas multi-modais
  profile: "vision-profile",
  preferredProfile: "vision-fallback"
}
```

```json5
{
  type: "cli",
  command: "gemini",
  args: [
    "-m",
    "gemini-3-flash",
    "--allowed-tools",
    "read_file",
    "Leia a m√≠dia em {{MediaPath}} e descreva-a em <= {{MaxChars}} caracteres."
  ],
  maxChars: 500,
  maxBytes: 52428800,
  timeoutSeconds: 120,
  capabilities: ["video", "image"]
}
```

Templates de CLI tamb√©m podem usar:

- `{{MediaDir}}` (diret√≥rio contendo o arquivo de m√≠dia)
- `{{OutputDir}}` (diret√≥rio tempor√°rio criado para esta execu√ß√£o)
- `{{OutputBase}}` (caminho base do arquivo tempor√°rio, sem extens√£o)

## Padr√µes e limites

Padr√µes recomendados:

- `maxChars`: **500** para imagem/v√≠deo (curto, amig√°vel para comandos)
- `maxChars`: **n√£o definido** para √°udio (transcri√ß√£o completa, a menos que voc√™ defina um limite)
- `maxBytes`:
  - imagem: **10MB**
  - √°udio: **20MB**
  - v√≠deo: **50MB**

Regras:

- Se a m√≠dia exceder `maxBytes`, aquele modelo √© pulado e o **pr√≥ximo modelo √© tentado**.
- Se o modelo retornar mais de `maxChars`, a sa√≠da √© truncada.
- `prompt` tem como padr√£o o simples ‚ÄúDescreva a {m√≠dia}.‚Äù mais a orienta√ß√£o `maxChars` (apenas imagem/v√≠deo).
- Se `<capability>.enabled: true`, mas nenhum modelo estiver configurado, o ZERO tenta o **modelo de resposta ativo** quando seu provedor suporta a capacidade.

### Auto-detectar entendimento de m√≠dia (padr√£o)

Se `tools.media.<capability>.enabled` **n√£o** estiver definido como `false` e voc√™ n√£o configurou modelos, o ZERO auto-detecta nesta ordem e **para na primeira op√ß√£o que funcionar**:

1) **CLIs Locais** (apenas √°udio; se instaladas)
   - `sherpa-onnx-offline` (exige `SHERPA_ONNX_MODEL_DIR` com encoder/decoder/joiner/tokens)
   - `whisper-cli` (`whisper-cpp`; usa `WHISPER_CPP_MODEL` ou o modelo tiny embutido)
   - `whisper` (CLI Python; baixa modelos automaticamente)
2) **Gemini CLI** (`gemini`) usando `read_many_files`
3) **Chaves de provedores**
   - √Åudio: OpenAI ‚Üí Groq ‚Üí Deepgram ‚Üí Google
   - Imagem: OpenAI ‚Üí Anthropic ‚Üí Google ‚Üí MiniMax
   - V√≠deo: Google

Para desativar a auto-detec√ß√£o, defina:

```json5
{
  tools: {
    media: {
      audio: {
        enabled: false
      }
    }
  }
}
```

Nota: A detec√ß√£o de bin√°rios √© feita pelo melhor esfor√ßo em macOS/Linux/Windows; certifique-se de que a CLI esteja no `PATH` (n√≥s expandimos `~`), ou defina um modelo CLI expl√≠cito com o caminho completo do comando.

## Capacidades (opcional)

Se voc√™ definir `capabilities`, a entrada s√≥ roda para esses tipos de m√≠dia. Para listas compartilhadas, o ZERO pode inferir padr√µes:

- `openai`, `anthropic`, `minimax`: **imagem**
- `google` (API Gemini): **imagem + √°udio + v√≠deo**
- `groq`: **√°udio**
- `deepgram`: **√°udio**

Para entradas de CLI, **defina o `capabilities` explicitamente** para evitar correspond√™ncias inesperadas. Se voc√™ omitir `capabilities`, a entrada √© eleg√≠vel para a lista em que aparece.

## Matriz de suporte de provedores (integra√ß√µes ZERO)

| Capacidade | Integra√ß√£o de Provedor | Notas |
|------------|------------------------|-------|
| Imagem | OpenAI / Anthropic / Google / outros via `pi-ai` | Qualquer modelo capaz de imagem no registro funciona. |
| √Åudio | OpenAI, Groq, Deepgram, Google | Transcri√ß√£o de provedor (Whisper/Deepgram/Gemini). |
| V√≠deo | Google (API Gemini) | Entendimento de v√≠deo do provedor. |

## Provedores recomendados

**Imagem**

- Prefira o seu modelo ativo se ele suportar imagens.
- Bons padr√µes: `openai/gpt-5.2`, `anthropic/claude-opus-4-5`, `google/gemini-3-pro-preview`.

**√Åudio**

- `openai/gpt-4o-mini-transcribe`, `groq/whisper-large-v3-turbo` ou `deepgram/nova-3`.
- Fallback de CLI: `whisper-cli` (whisper-cpp) ou `whisper`.
- Configura√ß√£o Deepgram: [Deepgram (transcri√ß√£o de √°udio)](/providers/deepgram).

**V√≠deo**

- `google/gemini-3-flash-preview` (r√°pido), `google/gemini-3-pro-preview` (mais rico).
- Fallback de CLI: CLI `gemini` (suporta `read_file` em v√≠deo/√°udio).

## Pol√≠tica de anexos

A configura√ß√£o de `attachments` por capacidade controla quais anexos s√£o processados:

- `mode`: `first` (primeiro, padr√£o) ou `all` (todos)
- `maxAttachments`: limita o n√∫mero processado (padr√£o **1**)
- `prefer`: `first`, `last`, `path`, `url`

Quando `mode: "all"`, as sa√≠das s√£o rotuladas como `[Image 1/2]`, `[Audio 2/2]`, etc.

## Exemplos de configura√ß√£o

### 1) Lista de modelos compartilhados + sobrescritas

```json5
{
  tools: {
    media: {
      models: [
        { provider: "openai", model: "gpt-5.2", capabilities: ["image"] },
        { provider: "google", model: "gemini-3-flash-preview", capabilities: ["image", "audio", "video"] },
        {
          type: "cli",
          command: "gemini",
          args: [
            "-m",
            "gemini-3-flash",
            "--allowed-tools",
            "read_file",
            "Leia a m√≠dia em {{MediaPath}} e descreva-a em <= {{MaxChars}} caracteres."
          ],
          capabilities: ["image", "video"]
        }
      ],
      audio: {
        attachments: { mode: "all", maxAttachments: 2 }
      },
      video: {
        maxChars: 500
      }
    }
  }
}
```

### 2) Apenas √Åudio + V√≠deo (imagem desativada)

```json5
{
  tools: {
    media: {
      audio: {
        enabled: true,
        models: [
          { provider: "openai", model: "gpt-4o-mini-transcribe" },
          {
            type: "cli",
            command: "whisper",
            args: ["--model", "base", "{{MediaPath}}"]
          }
        ]
      },
      video: {
        enabled: true,
        maxChars: 500,
        models: [
          { provider: "google", model: "gemini-3-flash-preview" },
          {
            type: "cli",
            command: "gemini",
            args: [
              "-m",
              "gemini-3-flash",
              "--allowed-tools",
              "read_file",
              "Leia a m√≠dia em {{MediaPath}} e descreva-a em <= {{MaxChars}} caracteres."
            ]
          }
        ]
      }
    }
  }
}
```

### 3) Entendimento de imagem opcional

```json5
{
  tools: {
    media: {
      image: {
        enabled: true,
        maxBytes: 10485760,
        maxChars: 500,
        models: [
          { provider: "openai", model: "gpt-5.2" },
          { provider: "anthropic", model: "claude-opus-4-5" },
          {
            type: "cli",
            command: "gemini",
            args: [
              "-m",
              "gemini-3-flash",
              "--allowed-tools",
              "read_file",
              "Leia a m√≠dia em {{MediaPath}} e descreva-a em <= {{MaxChars}} caracteres."
            ]
          }
        ]
      }
    }
  }
}
```

### 4) Entrada √∫nica multi-modal (capacidades expl√≠citas)

```json5
{
  tools: {
    media: {
      image: { models: [{ provider: "google", model: "gemini-3-pro-preview", capabilities: ["image", "video", "audio"] }] },
      audio: { models: [{ provider: "google", model: "gemini-3-pro-preview", capabilities: ["image", "video", "audio"] }] },
      video: { models: [{ provider: "google", model: "gemini-3-pro-preview", capabilities: ["image", "video", "audio"] }] }
    }
  }
}
```

## Sa√≠da de status

Quando o entendimento de m√≠dia √© executado, o `/status` inclui uma linha de resumo curta:

```
üìé Media: image ok (openai/gpt-5.2) ¬∑ audio skipped (maxBytes)
```

Isso mostra os resultados por capacidade e o provedor/modelo escolhido, quando aplic√°vel.

## Notas

- O entendimento √© feito por **melhor esfor√ßo**. Erros n√£o bloqueiam as respostas.
- Anexos ainda s√£o passados para os modelos mesmo quando o entendimento est√° desativado.
- Use `scope` para limitar onde o entendimento √© executado (ex: apenas DMs).

## Documentos relacionados

- [Configura√ß√£o](/gateway/configuration)
- [Suporte a Imagem & M√≠dia](/nodes/images)
